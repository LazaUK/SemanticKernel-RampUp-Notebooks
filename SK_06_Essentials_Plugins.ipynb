{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00088d4",
   "metadata": {},
   "source": [
    "## Semantic Kernel: Ramp-Up based on SK's Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d481c",
   "metadata": {},
   "source": [
    "To get the latest version of SK Python package, use:\n",
    "\n",
    "``` bash\n",
    "pip install --upgrade semantic-kernel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db6c3f",
   "metadata": {},
   "source": [
    "## ðŸ“’ Notebook 6: Plugins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e4fe7",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 1: Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ba3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import os\n",
    "import logging\n",
    "from typing import Dict, Any\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.functions import KernelArguments\n",
    "from semantic_kernel.functions.kernel_function_from_method import KernelFunctionFromMethod\n",
    "\n",
    "# For Azure Logic Apps management\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.mgmt.web import WebSiteManagementClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c91018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Azure OpenAI backend variables\n",
    "AOAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_API_DEPLOY\")\n",
    "AOAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "AOAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "\n",
    "# Set Azure Logic Apps variables\n",
    "SUBSCRIPTION_ID = os.getenv(\"AZURE_SUBSCRIPTION_ID\")\n",
    "RESOURCE_GROUP = os.getenv(\"RESOURCE_GROUP_NAME\", \"App_LogicApp\")\n",
    "LOGIC_APP_NAME = \"Laziz-StandardLA\"     # Your Standard Logic App name\n",
    "WORKFLOW_NAME = \"lazizdemologicapp\"     # Your workflow inside the Standard Logic App\n",
    "TRIGGER_NAME = \"HTTP-trigger-standard\"  # Your HTTP trigger name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f0f2e",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 2: Generate OpenAPI Spec for Logic App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a178fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ StandardLogicAppsOpenAPIHelper class defined\n"
     ]
    }
   ],
   "source": [
    "# Define helper class for Standard Logic Apps OpenAPI spec generation\n",
    "class StandardLogicAppsOpenAPIHelper:\n",
    "    \"\"\"\n",
    "    Helper class to generate OpenAPI spec for Standard Logic Apps.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, subscription_id: str, resource_group: str, credential=None):\n",
    "        if credential is None:\n",
    "            credential = DefaultAzureCredential()\n",
    "        \n",
    "        self.subscription_id = subscription_id\n",
    "        self.resource_group = resource_group\n",
    "        self.credential = credential\n",
    "        self.web_client = WebSiteManagementClient(credential, subscription_id)\n",
    "    \n",
    "    def get_callback_url(self, logic_app_name: str, workflow_name: str, trigger_name: str) -> str:\n",
    "        \"\"\"Get the callback URL with SAS token for a Standard Logic App workflow trigger.\"\"\"\n",
    "        try:\n",
    "            callback = self.web_client.workflow_triggers.list_callback_url(\n",
    "                resource_group_name = self.resource_group,\n",
    "                name = logic_app_name,\n",
    "                workflow_name = workflow_name,\n",
    "                trigger_name = trigger_name\n",
    "            )\n",
    "            if callback.value is None:\n",
    "                raise ValueError(f\"No callback URL returned for workflow '{workflow_name}' in Logic App '{logic_app_name}'.\")\n",
    "            print(f\"âœ“ Retrieved callback URL for workflow: {workflow_name}\")\n",
    "            return callback.value\n",
    "        except Exception as e:\n",
    "            print(f\"âœ— Error getting callback URL: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def create_openapi_spec(self, callback_url: str, operation_description: str = None) -> str:\n",
    "        \"\"\"\n",
    "        Create OpenAPI 3.0 spec with explicit SAS parameters for direct invocation.\n",
    "        \"\"\"\n",
    "        if operation_description is None:\n",
    "            operation_description = \"Get weather forecast for a specified location\"\n",
    "        from urllib.parse import urlparse, parse_qs\n",
    "        parsed_url = urlparse(callback_url)\n",
    "        base_url = f\"{parsed_url.scheme}://{parsed_url.netloc}{parsed_url.path}\"\n",
    "        query_params = parse_qs(parsed_url.query)\n",
    "        parameters_yaml = []\n",
    "        for param_name, param_values in query_params.items():\n",
    "            if param_values:\n",
    "                param_value = param_values[0]\n",
    "                param_entry = f\"\"\"        - name: {param_name}\n",
    "          in: query\n",
    "          required: true\n",
    "          schema:\n",
    "            type: string\n",
    "            default: '{param_value}'\"\"\"\n",
    "                parameters_yaml.append(param_entry)\n",
    "        parameters_section = \"\\n\".join(parameters_yaml)\n",
    "        openapi_yaml = f\"\"\"openapi: 3.0.0\n",
    "info:\n",
    "  title: Standard Logic App Weather API\n",
    "  version: 1.0.0\n",
    "  description: Weather forecast service via Azure Standard Logic App\n",
    "servers:\n",
    "  - url: {base_url}\n",
    "paths:\n",
    "  /:\n",
    "    post:\n",
    "      operationId: getWeatherForecast\n",
    "      summary: Get weather forecast\n",
    "      description: {operation_description}\n",
    "      parameters:\n",
    "{parameters_section}\n",
    "      requestBody:\n",
    "        required: true\n",
    "        content:\n",
    "          application/json:\n",
    "            schema:\n",
    "              type: object\n",
    "              properties:\n",
    "                Location:\n",
    "                  type: string\n",
    "                  description: The location to get weather forecast for\n",
    "              required:\n",
    "                - Location\n",
    "      responses:\n",
    "        '200':\n",
    "          description: Successful response\n",
    "\"\"\"\n",
    "        print(\"âœ“ OpenAPI spec with auth parameters created successfully\")\n",
    "        return openapi_yaml\n",
    "\n",
    "print(\"âœ“ StandardLogicAppsOpenAPIHelper class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e75b186f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Retrieved callback URL for workflow: lazizdemologicapp\n",
      "âœ“ OpenAPI spec with auth parameters created successfully\n",
      "\n",
      "======================================================================\n",
      "OpenAPI Specification Preview:\n",
      "======================================================================\n",
      "openapi: 3.0.0\n",
      "info:\n",
      "  title: Standard Logic App Weather API\n",
      "  version...\n"
     ]
    }
   ],
   "source": [
    "# Initialise the helper\n",
    "logic_helper = StandardLogicAppsOpenAPIHelper(\n",
    "    subscription_id = SUBSCRIPTION_ID,\n",
    "    resource_group = RESOURCE_GROUP\n",
    ")\n",
    "\n",
    "# Get callback URL\n",
    "callback_url = logic_helper.get_callback_url(\n",
    "    logic_app_name = LOGIC_APP_NAME,\n",
    "    workflow_name = WORKFLOW_NAME,\n",
    "    trigger_name = TRIGGER_NAME\n",
    ")\n",
    "\n",
    "# Generate OpenAPI spec\n",
    "openapi_spec = logic_helper.create_openapi_spec(\n",
    "    callback_url = callback_url,\n",
    "    operation_description = \"Get current weather forecast for any location worldwide\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OpenAPI Specification Preview:\")\n",
    "print(\"=\"*70)\n",
    "print(openapi_spec[:70] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f1baa",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 3: Add Logic App's OpenAPI plug-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67498941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise kernel\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41725f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a59c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Azure OpenAI chat completion\n",
    "chat_completion = AzureChatCompletion(\n",
    "    deployment_name = AOAI_DEPLOYMENT,\n",
    "    endpoint = AOAI_ENDPOINT,\n",
    "    api_version = AOAI_API_VERSION,\n",
    "    service_id = \"azure_openai_chat\",\n",
    ")\n",
    "\n",
    "kernel.add_service(chat_completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "772c007c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ OpenAPI spec saved locally\n",
      "âœ“ OpenAPI plugin 'WeatherPlugin' added to kernel successfully\n",
      "âœ“ Available functions: ['getWeatherForecast']\n"
     ]
    }
   ],
   "source": [
    "# Add the OpenAPI plugin to the kernel.\n",
    "try:\n",
    "    import os\n",
    "    spec_file_path = os.path.join(os.getcwd(), \"standard_logic_app_openapi.yaml\")\n",
    "    with open(spec_file_path, 'w') as f:\n",
    "        f.write(openapi_spec)\n",
    "    print(f\"âœ“ OpenAPI spec saved locally\")\n",
    "\n",
    "    plugin = kernel.add_plugin_from_openapi(\n",
    "        plugin_name=\"WeatherPlugin\",\n",
    "        openapi_document_path=spec_file_path\n",
    "    )\n",
    "    print(\"âœ“ OpenAPI plugin 'WeatherPlugin' added to kernel successfully\")\n",
    "    print(f\"âœ“ Available functions: {list(plugin.functions.keys())}\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error during plugin setup: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19d331",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 4: Invoke a prompt and observe telemetry in App Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b196bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "Direct Function Call Result:\n",
      "======================================================================\n",
      "Location: London\n",
      "Response: {\"responses\":{\"daily\":{\"day\":{\"cap\":\"Rain showers\",\"pvdrCap\":\"Rain showers\",\"pvdrWindDir\":\"241\",\"pvdrWindSpd\":\"15\",\"icon\":23,\"symbol\":\"d2200\",\"pvdrIcon\":\"23\",\"urlIcon\":\"http://img-s-msn-com.akamaized.net/tenant/amp/entityid/AAehOqC.img\",\"precip\":80.0,\"wx\":\"-RA\",\"sky\":\"SCT\",\"windDir\":241,\"windSpd\":15.0,\"summary\":\"Watch for scattered rain showers.  The high will be 13Â°.\",\"summaries\":[\"Watch for scattered rain showers.\",\" The high will be 13Â°.\"]},\"night\":{\"cap\":\"Light rain showers\",\"pvdrCap\":\"Light rain showers\",\"pvdrWindDir\":\"218\",\"pvdrWindSpd\":\"16\",\"icon\":46,\"symbol\":\"n2100\",\"pvdrIcon\":\"46\",\"urlIcon\":\"http://img-s-msn-com.akamaized.net/tenant/amp/entityid/AAehyQD.img\",\"precip\":59.0,\"wx\":\"-RA\",\"sky\":\"SCT\",\"windDir\":218,\"windSpd\":16.0,\"summary\":\"There will be scattered light rain showers.  The low will be 8Â°.\",\"summaries\":[\"There will be scattered light rain showers.\",\" The low will be 8Â°.\"]},\"pvdrCap\":\"Rain showers\",\"pvdrWindDir\":\"218\",\"pvdrWindSpd\":\"16\",\"valid\":\"2025-11-02T00:00:00+00:00\",\"icon\":23,\"symbol\":\"d2200\",\"pvdrIcon\":\"23\",\"iconUrl\":\"http://img-s-msn-com.akamaized.net/tenant/amp/entityid/AAehOqC.img\",\"precip\":80.0,\"windMax\":16.0,\"windMaxDir\":218,\"windTh\":28.8,\"rhHi\":90.0,\"rhLo\":58.0,\"tempHi\":13.0,\"tempLo\":8.0,\"uv\":1.0,\"uvDesc\":\"Low\",\"created\":\"2025-11-02T02:55:00+00:00\",\"rainAmount\":0.19,\"snowAmount\":0.0},\"almanac\":{\"valid\":\"2025-11-02T00:00:00+00:00\",\"sunrise\":\"2025-11-02T06:55:03+00:00\",\"sunset\":\"2025-11-02T16:32:15+00:00\",\"moonrise\":\"2025-11-02T15:05:17+00:00\",\"moonset\":\"2025-11-02T02:29:53+00:00\",\"moonState\":\"1\",\"moonPhase\":\"Waxing Gibbous\",\"moonPhaseCode\":\"WxGi\"},\"provider\":{\"name\":\"Foreca\",\"url\":\"http://www.foreca.com\"},\"source\":{\"id\":\"102643743\",\"coordinates\":{\"lat\":51.508419036865234,\"lon\":-0.12553000450134277},\"location\":\"London, Greater London, United Kingdom\",\"utcOffset\":\"00:00:00\",\"countryCode\":\"GB\"}},\"units\":{\"system\":\"Metric\",\"pressure\":\"mb\",\"temperature\":\"Â°C\",\"speed\":\"km/h\",\"height\":\"cm\",\"distance\":\"km\",\"time\":\"s\"},\"copyright\":\"Copyright Â© 2025 Microsoft and its suppliers. All rights reserved. This API cannot be accessed and the content and any results may not be used, reproduced or transmitted in any manner without express written permission from Microsoft Corporation.\"}\n"
     ]
    }
   ],
   "source": [
    "# Test the plugin by calling the function directly\n",
    "try:\n",
    "    # Get the function from the plugin\n",
    "    weather_function = kernel.plugins[\"WeatherPlugin\"][\"getWeatherForecast\"]\n",
    "    \n",
    "    # Parse the SAS tokens from the callback URL and normalize their names\n",
    "    from urllib.parse import urlparse, parse_qs\n",
    "    parsed_url = urlparse(callback_url)\n",
    "    query_params = parse_qs(parsed_url.query)\n",
    "\n",
    "    # Create arguments, replacing hyphens with underscores in the SAS token names\n",
    "    arguments = KernelArguments(\n",
    "        Location=\"London\",\n",
    "        **{k.replace(\"-\", \"_\"): v[0] for k, v in query_params.items()}\n",
    "    )\n",
    "    \n",
    "    # Invoke the function with all required arguments\n",
    "    result = await weather_function.invoke(kernel, arguments)\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"Direct Function Call Result:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"Location: London\")\n",
    "    print(f\"Response: {result}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error invoking function: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "111f235c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with auto function calling...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Enable auto function calling\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "\n",
    "# Create execution settings with auto function calling\n",
    "execution_settings = OpenAIChatPromptExecutionSettings(\n",
    "    service_id=\"azure_openai_chat\",\n",
    "    max_tokens=2000,\n",
    "    temperature=0.7,\n",
    "    top_p=0.8,\n",
    ")\n",
    "\n",
    "# Create a chat history\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_system_message(\n",
    "    \"You are a helpful weather assistant. When asked about weather, \"\n",
    "    \"use the getWeatherForecast function to get current weather information.\"\n",
    ")\n",
    "chat_history.add_user_message(\"What's the weather like in Paris?\")\n",
    "\n",
    "print(\"Testing with auto function calling...\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05117f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat Response:\n",
      "======================================================================\n",
      "User: What's the weather like in Paris?\n",
      "\n",
      "Assistant: Could you please specify if you want the current weather or the forecast for a specific date?\n"
     ]
    }
   ],
   "source": [
    "# Get chat completion with auto function calling\n",
    "try:\n",
    "    # Get the chat completion service\n",
    "    chat_service = kernel.get_service(\"azure_openai_chat\")\n",
    "    \n",
    "    # Get response (SK will automatically call the function if needed)\n",
    "    response = await chat_service.get_chat_message_content(\n",
    "        chat_history=chat_history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    print(\"Chat Response:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"User: What's the weather like in Paris?\")\n",
    "    print(f\"\\nAssistant: {response}\")\n",
    "    \n",
    "    # Add response to history for continued conversation\n",
    "    chat_history.add_assistant_message(str(response))\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error during chat completion: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27ae5f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Follow-up Response:\n",
      "======================================================================\n",
      "User: How about Tokyo?\n",
      "\n",
      "Assistant: Could you please specify if you want the current weather or the forecast for a specific date in Tokyo?\n"
     ]
    }
   ],
   "source": [
    "# Ask a follow-up question\n",
    "try:\n",
    "    chat_history.add_user_message(\"How about Tokyo?\")\n",
    "    \n",
    "    response = await chat_service.get_chat_message_content(\n",
    "        chat_history=chat_history,\n",
    "        settings=execution_settings,\n",
    "        kernel=kernel\n",
    "    )\n",
    "    \n",
    "    print(\"\\nFollow-up Response:\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"User: How about Tokyo?\")\n",
    "    print(f\"\\nAssistant: {response}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error during follow-up: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b6af44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full Conversation History:\n",
      "======================================================================\n",
      "\n",
      "System: You are a helpful weather assistant. When asked about weather, use the getWeatherForecast function to get current weather information.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "User: What's the weather like in Paris?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Assistant: Could you please specify if you want the current weather or the forecast for a specific date?\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "User: How about Tokyo?\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display the full conversation\n",
    "print(\"\\nFull Conversation History:\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for message in chat_history.messages:\n",
    "    role = message.role.value.capitalize()\n",
    "    content = message.content\n",
    "    print(f\"\\n{role}: {content}\")\n",
    "    print(\"-\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
