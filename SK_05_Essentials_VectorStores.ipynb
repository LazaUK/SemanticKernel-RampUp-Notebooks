{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "d00088d4",
      "metadata": {},
      "source": [
        "## Semantic Kernel: Ramp-Up based on SK's Documentation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c58d481c",
      "metadata": {},
      "source": [
        "To get the latest version of SK and PyPDF Python packages, use:\n",
        "\n",
        "``` bash\n",
        "pip install --upgrade semantic-kernel pypdf2\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6db6c3f",
      "metadata": {},
      "source": [
        "## ðŸ“’ Notebook 5: Vector Store\n",
        "\n",
        "This notebook uses SK's In-Memory connector to create In-Memory Vector Store with PDF Documents"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "645e4fe7",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 1: Configure environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "44ba3684",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required packages\n",
        "import os\n",
        "import logging\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Annotated\n",
        "from uuid import uuid4\n",
        "from pathlib import Path\n",
        "import traceback; \n",
        "\n",
        "# PDF processing\n",
        "import PyPDF2\n",
        "\n",
        "# Semantic Kernel imports\n",
        "from semantic_kernel import Kernel\n",
        "from semantic_kernel.contents import ChatHistory\n",
        "from semantic_kernel.connectors.ai.open_ai import (\n",
        "    AzureChatCompletion,\n",
        "    AzureTextEmbedding,\n",
        "    OpenAIEmbeddingPromptExecutionSettings,\n",
        "    OpenAIChatPromptExecutionSettings\n",
        ")\n",
        "\n",
        "# Memory and vector store imports\n",
        "from semantic_kernel.connectors.memory.in_memory import InMemoryVectorCollection\n",
        "from semantic_kernel.data import (\n",
        "    VectorSearchFilter,\n",
        "    VectorSearchOptions,\n",
        "    VectorStoreRecordDataField,\n",
        "    VectorStoreRecordKeyField,\n",
        "    VectorStoreRecordVectorField,\n",
        "    vectorstoremodel,\n",
        ")\n",
        "from semantic_kernel.data.const import DISTANCE_FUNCTION_DIRECTION_HELPER, DistanceFunction, IndexKind\n",
        "from semantic_kernel.data.vector_search import add_vector_to_records"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "85c91018",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set Azure OpenAI backend variables\n",
        "AOAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_API_DEPLOY\")\n",
        "AOAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
        "AOAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
        "AOAI_EMBEDDING = os.getenv(\"AZURE_OPENAI_API_DEPLOY_EMBED\")\n",
        "\n",
        "# Set data folder path\n",
        "DATA_FOLDER = \"data\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9a3f0f2e",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 2: Define Data Model and Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "data_model_cell",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set constants for vector search\n",
        "DISTANCE_FUNCTION = DistanceFunction.COSINE_SIMILARITY\n",
        "INDEX_KIND = IndexKind.IVF_FLAT\n",
        "\n",
        "# Class for vector store's data model\n",
        "@vectorstoremodel\n",
        "@dataclass\n",
        "class DocumentChunk:\n",
        "    \"\"\"Data model for document chunks with vector embeddings.\"\"\"\n",
        "    vector: Annotated[\n",
        "        list[float] | None,\n",
        "        VectorStoreRecordVectorField(\n",
        "            embedding_settings = {\"embedding\": OpenAIEmbeddingPromptExecutionSettings()},\n",
        "            index_kind = INDEX_KIND,\n",
        "            dimensions = 1536,\n",
        "            distance_function = DISTANCE_FUNCTION,\n",
        "            property_type = \"float\",\n",
        "        ),\n",
        "    ] = None\n",
        "    id: Annotated[str, VectorStoreRecordKeyField()] = field(default_factory=lambda: str(uuid4()))\n",
        "    content: Annotated[\n",
        "        str,\n",
        "        VectorStoreRecordDataField(\n",
        "            has_embedding = True,\n",
        "            embedding_property_name = \"vector\",\n",
        "            property_type = \"str\",\n",
        "            is_full_text_searchable = True,\n",
        "        ),\n",
        "    ] = \"content\"\n",
        "    document_name: Annotated[str, VectorStoreRecordDataField(property_type=\"str\", is_filterable=True)] = \"document\"\n",
        "    page_number: Annotated[int, VectorStoreRecordDataField(property_type=\"int\", is_filterable=True)] = 0\n",
        "    chunk_index: Annotated[int, VectorStoreRecordDataField(property_type=\"int\", is_filterable=True)] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "helper_functions",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper function to extract text from PDF files\n",
        "def extract_text_from_pdf(pdf_path: Path) -> list[tuple[str, int]]:\n",
        "    \"\"\"Extract text from PDF file, returning list of (text, page_number) tuples.\"\"\"\n",
        "    pages_text = []\n",
        "    \n",
        "    try:\n",
        "        with open(pdf_path, 'rb') as file:\n",
        "            pdf_reader = PyPDF2.PdfReader(file)\n",
        "            for page_num, page in enumerate(pdf_reader.pages, 1):\n",
        "                text = page.extract_text()\n",
        "                if text.strip():  # Only add non-empty pages\n",
        "                    pages_text.append((text.strip(), page_num))\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading PDF {pdf_path}: {e}\")\n",
        "    \n",
        "    return pages_text\n",
        "\n",
        "# Helper function to split text into smaller pieces\n",
        "def chunk_text(text: str, chunk_size: int = 1000, overlap: int = 100) -> list[str]:\n",
        "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
        "    if len(text) <= chunk_size:\n",
        "        return [text]\n",
        "    \n",
        "    chunks = []\n",
        "    start = 0\n",
        "    \n",
        "    while start < len(text):\n",
        "        end = start + chunk_size\n",
        "        chunk = text[start:end]\n",
        "        \n",
        "        # Try to break at sentence boundary if possible\n",
        "        if end < len(text):\n",
        "            last_period = chunk.rfind('.')\n",
        "            if last_period > chunk_size // 2:  # Only break if it's not too early\n",
        "                chunk = chunk[:last_period + 1]\n",
        "                end = start + len(chunk)\n",
        "        \n",
        "        chunks.append(chunk)\n",
        "        start = end - overlap\n",
        "        \n",
        "        if end >= len(text):\n",
        "            break\n",
        "    \n",
        "    return chunks\n",
        "\n",
        "# Helper function to process all PDF files in a folder and return DocumentChunk objects\n",
        "def process_pdfs_from_folder(folder_path: str) -> list[DocumentChunk]:\n",
        "    \"\"\"Process all PDF files in the specified folder and return DocumentChunk objects.\"\"\"\n",
        "    data_path = Path(folder_path)\n",
        "    \n",
        "    if not data_path.exists():\n",
        "        print(f\"Warning: Data folder '{folder_path}' does not exist.\")\n",
        "        return []\n",
        "    \n",
        "    document_chunks = []\n",
        "    pdf_files = list(data_path.glob(\"*.pdf\"))\n",
        "    \n",
        "    if not pdf_files:\n",
        "        print(f\"No PDF files found in '{folder_path}'.\")\n",
        "        return []\n",
        "    \n",
        "    print(f\"Found {len(pdf_files)} PDF files to process:\")\n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"  - {pdf_file.name}\")\n",
        "    \n",
        "    for pdf_file in pdf_files:\n",
        "        print(f\"\\nProcessing: {pdf_file.name}\")\n",
        "        pages_text = extract_text_from_pdf(pdf_file)\n",
        "        \n",
        "        for page_text, page_num in pages_text:\n",
        "            chunks = chunk_text(page_text)\n",
        "            # print(f\"  Page {page_num}: {len(chunks)} chunks\")\n",
        "            \n",
        "            for chunk_idx, chunk in enumerate(chunks):\n",
        "                document_chunk = DocumentChunk(\n",
        "                    content = chunk,\n",
        "                    document_name = pdf_file.stem,  # filename without extension\n",
        "                    page_number = page_num,\n",
        "                    chunk_index = chunk_idx\n",
        "                )\n",
        "                document_chunks.append(document_chunk)\n",
        "    \n",
        "    print(f\"\\nTotal chunks created: {len(document_chunks)}\")\n",
        "    return document_chunks\n",
        "\n",
        "# Helper function to print search results\n",
        "def print_search_result(result, score: float = None):\n",
        "    \"\"\"Print a search result in a formatted way.\"\"\"\n",
        "    print(f\"Document: {result.document_name}\")\n",
        "    print(f\"Page: {result.page_number}, Chunk: {result.chunk_index}\")\n",
        "    if score is not None:\n",
        "        print(f\"Relevance Score: {score:.4f}\")\n",
        "    print(f\"Content: {result.content[:200]}{'...' if len(result.content) > 200 else ''}\")\n",
        "    print(\"-\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "043f1baa",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 3: Initialise Kernel and Services"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "67498941",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialise kernel\n",
        "kernel = Kernel()\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.ERROR)\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "3f23ef98",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure OpenAI embedding service added\n"
          ]
        }
      ],
      "source": [
        "# Add Azure OpenAI embedding\n",
        "if AOAI_EMBEDDING and AOAI_ENDPOINT and AOAI_API_VERSION:\n",
        "    embedder = AzureTextEmbedding(\n",
        "        deployment_name = AOAI_EMBEDDING,\n",
        "        endpoint = AOAI_ENDPOINT,\n",
        "        api_version = AOAI_API_VERSION,\n",
        "        service_id = \"embedding\"\n",
        "    )\n",
        "    kernel.add_service(embedder)\n",
        "    print(\"Azure OpenAI embedding service added\")\n",
        "else:\n",
        "    print(\"Azure OpenAI embedding not configured\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0a59c9ee",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Azure OpenAI chat completion service added\n"
          ]
        }
      ],
      "source": [
        "# Add Azure OpenAI chat completion\n",
        "if AOAI_DEPLOYMENT and AOAI_ENDPOINT and AOAI_API_VERSION:\n",
        "    chat_completion = AzureChatCompletion(\n",
        "        deployment_name = AOAI_DEPLOYMENT,\n",
        "        endpoint = AOAI_ENDPOINT,\n",
        "        api_version = AOAI_API_VERSION,\n",
        "        service_id = \"azure_openai_chat\",\n",
        "    )\n",
        "    kernel.add_service(chat_completion)\n",
        "    print(\"Azure OpenAI chat completion service added\")\n",
        "else:\n",
        "    print(\"Azure OpenAI chat completion not configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "pdf_processing",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 4: Load and Process PDF Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "load_pdfs",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing PDF documents from data folder...\n",
            "Found 2 PDF files to process:\n",
            "  - NorthwindHealthPlus_BenefitsDetails.pdf\n",
            "  - Northwind_Standard_Benefits_Details.pdf\n",
            "\n",
            "Processing: NorthwindHealthPlus_BenefitsDetails.pdf\n",
            "\n",
            "Processing: Northwind_Standard_Benefits_Details.pdf\n",
            "\n",
            "Total chunks created: 684\n",
            "Successfully processed 684 document chunks\n",
            "\n",
            "Document Summary:\n",
            "- NorthwindHealthPlus_BenefitsDetails: 109 pages, 344 chunks\n",
            "- Northwind_Standard_Benefits_Details: 104 pages, 340 chunks\n"
          ]
        }
      ],
      "source": [
        "# Process PDF documents from the data folder\n",
        "print(\"Processing PDF documents from data folder...\")\n",
        "document_chunks = process_pdfs_from_folder(DATA_FOLDER)\n",
        "\n",
        "if not document_chunks:\n",
        "    print(\"No documents to process. Please ensure PDF files are in the 'data' folder.\")\n",
        "else:\n",
        "    print(f\"Successfully processed {len(document_chunks)} document chunks\")\n",
        "    \n",
        "    # Display summary\n",
        "    doc_summary = {}\n",
        "    for chunk in document_chunks:\n",
        "        if chunk.document_name not in doc_summary:\n",
        "            doc_summary[chunk.document_name] = {'pages': set(), 'chunks': 0}\n",
        "        doc_summary[chunk.document_name]['pages'].add(chunk.page_number)\n",
        "        doc_summary[chunk.document_name]['chunks'] += 1\n",
        "    \n",
        "    print(\"\\nDocument Summary:\")\n",
        "    for doc_name, info in doc_summary.items():\n",
        "        print(f\"- {doc_name}: {len(info['pages'])} pages, {info['chunks']} chunks\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "vector_store",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 5: Create Vector Store and Upsert Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "create_vector_store",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating vector store collection...\n",
            "Collection created\n",
            "Generating embeddings for document chunks...\n",
            "Upserting records to vector store...\n",
            "Upserted 684 records to vector store\n"
          ]
        }
      ],
      "source": [
        "# Create and populate the vector store\n",
        "async def create_and_populate_vector_store():\n",
        "    if not document_chunks:\n",
        "        print(\"No document chunks to process\")\n",
        "        return None\n",
        "    \n",
        "    print(\"Creating vector store collection...\")\n",
        "    \n",
        "    # Create the collection\n",
        "    record_collection = InMemoryVectorCollection[str, DocumentChunk](\n",
        "        collection_name = \"pdf_documents\",\n",
        "        data_model_type = DocumentChunk,\n",
        "    )\n",
        "    \n",
        "    async with record_collection:\n",
        "        # Create the collection after wiping it\n",
        "        await record_collection.delete_collection()\n",
        "        await record_collection.create_collection_if_not_exists()\n",
        "        print(\"Collection created\")\n",
        "        \n",
        "        # Generate embeddings and upsert records\n",
        "        print(\"Generating embeddings for document chunks...\")\n",
        "        records_with_embedding = await add_vector_to_records(\n",
        "            kernel, document_chunks, data_model_type=DocumentChunk\n",
        "        )\n",
        "        \n",
        "        print(\"Upserting records to vector store...\")\n",
        "        keys = await record_collection.upsert(records_with_embedding)\n",
        "        print(f\"Upserted {len(keys)} records to vector store\")\n",
        "        \n",
        "        return record_collection\n",
        "\n",
        "# Run the async function\n",
        "vector_collection = await create_and_populate_vector_store()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "search_demo",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 6: Search Demos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "19c9b72a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search functions ready.\n"
          ]
        }
      ],
      "source": [
        "# Search documents in the vector store\n",
        "async def search_documents(query: str, document_filter: str = None, top_k: int = 5):\n",
        "    \"\"\"Search for documents based on a query, prints results and returns them.\"\"\"\n",
        "\n",
        "    print(f\"Searching for: '{query}'\")\n",
        "    if document_filter:\n",
        "        print(f\"Filtering by document: {document_filter}\")\n",
        "\n",
        "    retrieved_data = []\n",
        "\n",
        "    # Set up search options\n",
        "    if document_filter:\n",
        "        search_filter = VectorSearchFilter.equal_to(\"document_name\", document_filter)\n",
        "        options = VectorSearchOptions(\n",
        "            vector_field_name = \"vector\",\n",
        "            include_vectors = False,\n",
        "            filter = search_filter,\n",
        "            top = top_k\n",
        "        )\n",
        "    else:\n",
        "        options = VectorSearchOptions(\n",
        "            vector_field_name = \"vector\",\n",
        "            include_vectors = False,\n",
        "            top = top_k\n",
        "        )\n",
        "    \n",
        "    try:\n",
        "        # Generate embedding for the query\n",
        "        query_embedding = (await embedder.generate_raw_embeddings([query]))[0]\n",
        "        \n",
        "        # Perform the search\n",
        "        async with vector_collection:\n",
        "            search_results = await vector_collection.vectorized_search(\n",
        "                vector = query_embedding,\n",
        "                options = options,\n",
        "            )\n",
        "            \n",
        "            results_to_process = []\n",
        "            async for result_item in search_results.results:\n",
        "                results_to_process.append(result_item)\n",
        "\n",
        "            if not results_to_process:\n",
        "                print(\"No results found\")\n",
        "                return []\n",
        "            \n",
        "            print(f\"\\nFound {len(results_to_process)} matching results (max to use - {top_k}):\")\n",
        "            print(\"=\" * 80)\n",
        "            \n",
        "            for result in results_to_process:\n",
        "                # print_search_result(result.record, result.score)\n",
        "                retrieved_data.append((result.record, result.score))\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"Search error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return []\n",
        "        \n",
        "    return retrieved_data\n",
        "\n",
        "print(\"Search functions ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "search_example1",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for: 'Tips for Employees'\n",
            "\n",
            "Found 3 matching results (max to use - 3):\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(DocumentChunk(vector=None, id='22d3d1da-ddf2-4123-8560-ef69c6cb334a', content=\"2. Ask questions. If the employee is unsure about any part of the plan, it is important to ask \\nquestions in order to make sure that the plan is suitable for their needs.  \\n3. Research other plans. It is important to r esearch other plans and compare them to \\nNorthwind Standard in order to determine which plan is the best option.  \\n4. Verify the information. If the employee is unsure about the accuracy of any information \\nthat Northwind Health provides, it is important to ve rify the information with a trusted \\nsource.  \\nBy following these tips, employees can make sure that they are not misled by Northwind \\nHealth's intentionally false or misleading statements. It is important for employees to be \\naware of any potential inaccuraci es or false information that Northwind Health may use \\nwhen discussing their plans in order to make the most informed decision possible.\", document_name='Northwind_Standard_Benefits_Details', page_number=92, chunk_index=0),\n",
              "  0.824000597005297),\n",
              " (DocumentChunk(vector=None, id='8d043bf7-6c00-4fe8-bb4a-c65ee641db03', content='and responsibilities under the \\nlaw when it comes to their employer -provided health insurance plan. Here are a few tips \\nemployees should keep in mind:  \\nâ€¢ Be aware of the terms of your h ealth plan: itâ€™s important to understand how your plan \\nworks and what it covers.  \\nâ€¢ Keep track of any changes to the plan: employers are required to provide employees with \\nnotice of any material changes to the plan.  \\nâ€¢ Know your rights under COBRA: if you lo se your job or otherwise qualify for COBRA, you \\nmay be able to continue your coverage for a certain period of time.', document_name='Northwind_Standard_Benefits_Details', page_number=86, chunk_index=2),\n",
              "  0.8146848746320927),\n",
              " (DocumentChunk(vector=None, id='3961dd24-1c9e-42d5-b13a-738ab4c49442', content='loyees should also be sure to provide a clear and concise explanation of their complaint \\nor appeal. This explanation should include the dates of service, the providers involved, and \\nthe reason for the complaint or appeal. Em ployees should also be sure to provide any and \\nall supporting documentation when filing a complaint or appeal.', document_name='NorthwindHealthPlus_BenefitsDetails', page_number=88, chunk_index=3),\n",
              "  0.8059476759864235)]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 1: General search\n",
        "await search_documents(\"Tips for Employees\", top_k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "6119ad4f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for: 'What is covered by the Northwind Health Standard Plan?'\n",
            "Filtering by document: Northwind_Standard_Benefits_Details\n",
            "\n",
            "Found 3 matching results (max to use - 3):\n",
            "================================================================================\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[(DocumentChunk(vector=None, id='d2024f6b-392f-41e5-859a-ad367562f111', content='Summary of Benefits  \\nNorthwind Standard  \\nNorthwind Standard is a basic plan that provides coverage for medical, vision, a nd dental \\nservices. This plan also offers coverage for preventive care services, as well as prescription \\ndrug coverage. With Northwind Standard, you can choose from a variety of in -network \\nproviders, including primary care physicians, specialists, hospital s, and pharmacies. This \\nplan does not offer coverage for emergency services, mental health and substance abuse \\ncoverage, or out -of-network services.  \\nSUMMARY OF YOUR COSTS  \\nSummary of Your Costs  \\nWhen you choose Northwind Standard as your health plan, you can  rest assured that you \\nare getting comprehensive coverage at an affordable cost. Here, we will explain the various \\ncosts associated with this plan so that you know what to expect when it comes to your out -\\nof-pocket expenses.  \\nPremiums  \\nPremiums are the amou nt of money that you will need to pay each month for your coverage.', document_name='Northwind_Standard_Benefits_Details', page_number=3, chunk_index=0),\n",
              "  0.9067803547588762),\n",
              " (DocumentChunk(vector=None, id='2736c062-8bf2-45c4-bc9f-9c20e1b063b3', content='nd Health may use \\nwhen discussing their plans in order to make the most informed decision possible.  \\nMember Cooperation  \\nMEMBER COOPERATION  \\nAt Northwind Health, we understand that people are more likely to get the care the y need \\nwhen they are informed and empowered with the knowledge they need. That is why we \\nhave included the following information in our Northwind Standard plan to help inform and \\nempower our members.  \\nWhen you sign up for the Northwind Standard plan, you are agreeing to certain \\nresponsibilities as a member of the plan. This includes being aware of the planâ€™s benefits \\nand limitations, as well as your obligations under the plan.  \\nCovering Your Expenses  \\nWhen you are enrolled in Northwind Standard, your plan will cover a portion of your \\nmedical and vision expenses. However, you may be responsible for certain co -payments or \\nco-insurance amounts.', document_name='Northwind_Standard_Benefits_Details', page_number=92, chunk_index=1),\n",
              "  0.906764736463156),\n",
              " (DocumentChunk(vector=None, id='f9dfba50-205a-4770-a4c9-d320ffe75f38', content='ant to note that while Northwind Standard covers a variety of services, there are \\nsome except ions. These include emergency services, mental health and substance abuse \\ncoverage, and out -of-network services. If you need any of these services, be sure to contact \\nNorthwind Health to verify coverage.  \\nWe hope that this information has been helpful in u nderstanding the plan and your rights \\nand responsibilities as a member of Northwind Standard. For more information, contact \\nNorthwind Health or visit our website.', document_name='Northwind_Standard_Benefits_Details', page_number=93, chunk_index=2),\n",
              "  0.9062712212425219)]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Example 2: Search within a specific document\n",
        "await search_documents(\n",
        "    query = \"What is covered by the Northwind Health Standard Plan?\",\n",
        "    document_filter = \"Northwind_Standard_Benefits_Details\",\n",
        "    top_k = 3\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c949b55d",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 7: RAG with PDF Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "a09b45ed",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RAG function is ready.\n"
          ]
        }
      ],
      "source": [
        "# Perform a Retrieval Augmented Generation (RAG) query\n",
        "async def perform_rag_query(\n",
        "    query: str,\n",
        "    document_filter: str = None,\n",
        "    top_k_retrieval: int = 3,\n",
        "    chat_service_id: str = \"azure_openai_chat\" \n",
        "):\n",
        "    \"\"\"\n",
        "    Performs Retrieval Augmented Generation (Simplified):\n",
        "    1. Uses search_documents to retrieve relevant document chunks.\n",
        "    2. Constructs a ChatHistory object with a system and user messages.\n",
        "    3. Calls the chat service's get_chat_message_contents method.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        chat_completion_service = kernel.get_service(chat_service_id)\n",
        "    except Exception as e:\n",
        "        print(f\"Error getting chat service '{chat_service_id}' for RAG: {e}\")\n",
        "        return\n",
        "\n",
        "    # --- 1. Retrieve relevant document chunks using search_documents ---\n",
        "    search_results_tuples = await search_documents(\n",
        "        query = query,\n",
        "        document_filter = document_filter,\n",
        "        top_k = top_k_retrieval\n",
        "    )\n",
        "\n",
        "    retrieved_chunks_content = []\n",
        "    if not search_results_tuples:\n",
        "        print(\"No document chunks retrieved by search_documents to use for context.\")\n",
        "    else:\n",
        "        # print(f\"\\nUsing {len(search_results_tuples)} retrieved chunk(s) for context generation:\")\n",
        "        for record, score in search_results_tuples:\n",
        "            retrieved_chunks_content.append(record.content)\n",
        "            # print(f\"      - RAG Context: Doc: {record.document_name}, Page: {record.page_number}, Chunk: {record.chunk_index}, Score: {score:.4f} (Content snippet: '{record.content[:50].strip()}...')\")\n",
        "\n",
        "    # --- 2. Construct ChatHistory ---\n",
        "    chat_history = ChatHistory()\n",
        "    system_message = (\n",
        "        \"You are a helpful AI assistant. You are provided with context from documents. \"\n",
        "        \"Your task is to answer the user's question based ONLY on this provided context. \"\n",
        "        \"Do not use any external knowledge or make assumptions beyond what is stated in the context. \"\n",
        "        \"If the information to answer the question is not present in the context, \"\n",
        "        \"clearly state that you cannot answer based on the provided information. \"\n",
        "        \"Be concise and directly answer the question.\"\n",
        "    )\n",
        "    chat_history.add_system_message(system_message)\n",
        "\n",
        "    if retrieved_chunks_content:\n",
        "        context_str = \"\\n\\n---\\n\\n\".join(retrieved_chunks_content)\n",
        "        user_message_text = f\"\"\"Here is the context from the documents:\n",
        "<context>\n",
        "{context_str}\n",
        "</context>\n",
        "\n",
        "Based ONLY on the context provided above, please answer the following question.\n",
        "User Question: {query}\"\"\"\n",
        "        # print(f\"\\nContext prepared for LLM (using {len(retrieved_chunks_content)} chunk(s)).\")\n",
        "    else:\n",
        "        user_message_text = f\"\"\"User Question: {query}\n",
        "\n",
        "(System note: No specific context was retrieved for this question from the documents. \n",
        "Based on your instructions, if the answer is not in the documents, please state that.)\"\"\"\n",
        "\n",
        "    chat_history.add_user_message(user_message_text)\n",
        "\n",
        "    # --- 3. Generate an answer using the chat service's get_chat_message_contents ---\n",
        "    try:\n",
        "        execution_settings = OpenAIChatPromptExecutionSettings(\n",
        "            service_id = chat_service_id,\n",
        "        )\n",
        "        \n",
        "        response_messages = await chat_completion_service.get_chat_message_contents(\n",
        "            chat_history = chat_history,\n",
        "            settings = execution_settings\n",
        "        )\n",
        "\n",
        "        print(\"\\nLLM Response:\")\n",
        "        if response_messages and isinstance(response_messages, list) and len(response_messages) > 0:\n",
        "            assistant_message_content = response_messages[0]\n",
        "            if hasattr(assistant_message_content, 'content') and assistant_message_content.content is not None:\n",
        "                 print(str(assistant_message_content.content))\n",
        "            elif hasattr(assistant_message_content, 'items') and assistant_message_content.items and \\\n",
        "                 hasattr(assistant_message_content.items[0], 'text'):\n",
        "                 print(assistant_message_content.items[0].text)\n",
        "            else: \n",
        "                 print(str(assistant_message_content))\n",
        "        else:\n",
        "            print(\"\\nLLM returned an empty or unexpected response format.\")\n",
        "            print(f\"Raw response: {response_messages}\")\n",
        "\n",
        "    except AttributeError as e:\n",
        "        print(f\"AttributeError during LLM invocation: {e}\")\n",
        "        traceback.print_exc()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during LLM invocation: {e}\")\n",
        "        traceback.print_exc()\n",
        "\n",
        "print(\"RAG function is ready.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "2423d0d9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Searching for: 'What are the key benefits of the Northwind Health Plus plan?'\n",
            "\n",
            "Found 3 matching results (max to use - 3):\n",
            "================================================================================\n",
            "\n",
            "LLM Response:\n",
            "The key benefits of the Northwind Health Plus plan include comprehensive coverage for medical, vision, and dental services, prescription drug coverage, mental health and substance abuse coverage, and preventive care services. The plan allows you to choose from a variety of in-network providers, including primary care physicians, specialists, hospitals, and pharmacies. It also offers coverage for emergency services both in-network and out-of-network.\n",
            "\n",
            "================================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# General RAG query across all documents\n",
        "await perform_rag_query(\n",
        "    query=\"What are the key benefits of the Northwind Health Plus plan?\",\n",
        "    top_k_retrieval=3\n",
        ")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cleanup",
      "metadata": {},
      "source": [
        "### ðŸªœ Step 8: Cleanup (Optional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "cleanup_cell",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector collection cleaned up\n"
          ]
        }
      ],
      "source": [
        "# Clean up the vector collection\n",
        "async def cleanup_collection():\n",
        "    if vector_collection:\n",
        "        try:\n",
        "            async with vector_collection:\n",
        "                await vector_collection.delete_collection()\n",
        "            print(\"Vector collection cleaned up\")\n",
        "        except Exception as e:\n",
        "            print(f\"Cleanup error: {e}\")\n",
        "    else:\n",
        "        print(\"No collection to clean up\")\n",
        "\n",
        "await cleanup_collection()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
