{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d00088d4",
   "metadata": {},
   "source": [
    "## Semantic Kernel: Ramp-Up based on SK's Documentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d481c",
   "metadata": {},
   "source": [
    "To get the latest version of SK Python package, use:\n",
    "\n",
    "``` bash\n",
    "pip install --upgrade semantic-kernel\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6db6c3f",
   "metadata": {},
   "source": [
    "## ðŸ“’ Notebook 4: Observability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e4fe7",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 1: Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44ba3684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import asyncio\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# OpenTelemetry imports for Azure Monitor\n",
    "from azure.monitor.opentelemetry.exporter import (\n",
    "    AzureMonitorLogExporter,\n",
    "    AzureMonitorMetricExporter,\n",
    "    AzureMonitorTraceExporter,\n",
    ")\n",
    "from opentelemetry._logs import set_logger_provider\n",
    "from opentelemetry.metrics import set_meter_provider\n",
    "from opentelemetry.sdk._logs import LoggerProvider, LoggingHandler\n",
    "from opentelemetry.sdk._logs.export import BatchLogRecordProcessor\n",
    "from opentelemetry.sdk.metrics import MeterProvider\n",
    "from opentelemetry.sdk.metrics.export import PeriodicExportingMetricReader\n",
    "from opentelemetry.sdk.metrics.view import DropAggregation, View\n",
    "from opentelemetry.sdk.resources import Resource\n",
    "from opentelemetry.sdk.trace import TracerProvider\n",
    "from opentelemetry.sdk.trace.export import BatchSpanProcessor\n",
    "from opentelemetry.semconv.resource import ResourceAttributes\n",
    "from opentelemetry.trace import set_tracer_provider\n",
    "\n",
    "# Semantic Kernel imports\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.contents import ChatHistory\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatCompletion\n",
    "\n",
    "# Azure AI Inference imports\n",
    "from azure.ai.inference.aio import ChatCompletionsClient\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatPromptExecutionSettings\n",
    "from azure.identity.aio import DefaultAzureCredential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85c91018",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Azure OpenAI backend variables\n",
    "AOAI_DEPLOYMENT = os.getenv(\"AZURE_OPENAI_API_DEPLOY\")\n",
    "AOAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_API_BASE\")\n",
    "AOAI_API_VERSION = os.getenv(\"AZURE_OPENAI_API_VERSION\")\n",
    "AZURE_APPINSIGHTS = os.getenv(\"AZURE_APPINSIGHTS_CONNSTRING\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f0f2e",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 2: Set up OpenTelemetry for Logging, Tracing and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88aca464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Application Insights Connection String: 'Instrumentation...' (truncated for display)\n",
      "Service Resource Name: 'semantic-kernel-observability-notebook'\n"
     ]
    }
   ],
   "source": [
    "# Create App Insights resource to represent SK application\n",
    "resource = Resource.create({ResourceAttributes.SERVICE_NAME: \"semantic-kernel-observability-notebook\"})\n",
    "\n",
    "print(f\"Application Insights Connection String: '{AZURE_APPINSIGHTS[:15]}...' (truncated for display)\")\n",
    "print(f\"Service Resource Name: '{resource.attributes[ResourceAttributes.SERVICE_NAME]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44cc1ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to send telemetry to Azure App Insights\n",
    "def set_up_logging():\n",
    "    \"\"\"Configures OpenTelemetry for logging.\"\"\"\n",
    "    exporter = AzureMonitorLogExporter(connection_string=AZURE_APPINSIGHTS)\n",
    "    logger_provider = LoggerProvider(resource=resource)\n",
    "    logger_provider.add_log_record_processor(BatchLogRecordProcessor(exporter))\n",
    "    set_logger_provider(logger_provider)\n",
    "\n",
    "    handler = LoggingHandler()\n",
    "    # Filter to only process records from semantic_kernel\n",
    "    handler.addFilter(logging.Filter(\"semantic_kernel\"))\n",
    "    logger = logging.getLogger()\n",
    "    logger.addHandler(handler)\n",
    "    logger.setLevel(logging.INFO)\n",
    "    print(\"  - Logging setup complete.\")\n",
    "\n",
    "def set_up_tracing():\n",
    "    \"\"\"Configures OpenTelemetry for tracing.\"\"\"\n",
    "    exporter = AzureMonitorTraceExporter(connection_string=AZURE_APPINSIGHTS)\n",
    "    tracer_provider = TracerProvider(resource=resource)\n",
    "    tracer_provider.add_span_processor(BatchSpanProcessor(exporter))\n",
    "    set_tracer_provider(tracer_provider)\n",
    "    print(\"  - Tracing setup complete.\")\n",
    "\n",
    "def set_up_metrics():\n",
    "    \"\"\"Configures OpenTelemetry for metrics.\"\"\"\n",
    "    exporter = AzureMonitorMetricExporter(connection_string=AZURE_APPINSIGHTS)\n",
    "    meter_provider = MeterProvider(\n",
    "        metric_readers=[PeriodicExportingMetricReader(exporter, export_interval_millis=5000)],\n",
    "        resource=resource,\n",
    "        views=[\n",
    "            # Drop all instrument names except for those starting with \"semantic_kernel\"\n",
    "            View(instrument_name=\"*\", aggregation=DropAggregation()),\n",
    "            View(instrument_name=\"semantic_kernel*\"),\n",
    "        ],\n",
    "    )\n",
    "    set_meter_provider(meter_provider)\n",
    "    print(\"  - Metrics setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3404d5ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Logging setup complete.\n",
      "  - Tracing setup complete.\n",
      "  - Metrics setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Enable telemetry\n",
    "set_up_logging()\n",
    "set_up_tracing()\n",
    "set_up_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043f1baa",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 3: Add AOAI Chat Completion service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67498941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise kernel\n",
    "kernel = Kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41725f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.ERROR)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a59c9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Azure OpenAI chat completion\n",
    "chat_completion = AzureChatCompletion(\n",
    "    deployment_name = AOAI_DEPLOYMENT,\n",
    "    endpoint = AOAI_ENDPOINT,\n",
    "    api_version = AOAI_API_VERSION,\n",
    "    service_id = \"azure_openai_chat\",\n",
    ")\n",
    "\n",
    "kernel.add_service(chat_completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19d331",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 4: Invoke a prompt and observe telemetry in App Insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe8d48",
   "metadata": {},
   "source": [
    "After execution of this cell, you should be able to find traces and dependency logging in Azure App Insights (under Investigate -> Transaction Search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d199dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Answer: Red pandas use their bushy tails not only for balance but also as a cozy blanket to keep warm in their cold mountain habitats.\n"
     ]
    }
   ],
   "source": [
    "# Invoke a simple prompt\n",
    "try:\n",
    "    answer = await kernel.invoke_prompt(\"Tell me an interesting fact about red pandas in one sentence.\")\n",
    "    print(f\"AI Answer: {answer}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during prompt invocation: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ab3038",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 5: Add Azure AI Inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7abdd56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define AI Inference chat completion\n",
    "chat_completion_service = AzureAIInferenceChatCompletion(\n",
    "    ai_model_id = AOAI_DEPLOYMENT,\n",
    "    client = ChatCompletionsClient(\n",
    "        api_version = AOAI_API_VERSION,\n",
    "        endpoint = f\"{str(AOAI_ENDPOINT).strip('/')}/openai/deployments/{AOAI_DEPLOYMENT}\",\n",
    "        credential = DefaultAzureCredential(),\n",
    "        credential_scopes = [\"https://cognitiveservices.azure.com/.default\"],\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd822b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add AI Inference service to the kernel\n",
    "kernel.add_service(chat_completion_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0f2a34",
   "metadata": {},
   "source": [
    "### ðŸªœ Step 6: Invoke a prompt and observe telemetry in Azure AI Foundry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15a45a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define execution settings\n",
    "execution_settings = AzureAIInferenceChatPromptExecutionSettings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "479813e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise chat history\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Tell me an interesting fact about red pandas in one sentence.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ef4f035d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI Inference Answer: Red pandas have a false thumbâ€”an extended wrist boneâ€”that helps them grasp bamboo while climbing trees.\n"
     ]
    }
   ],
   "source": [
    "# Non-streaming chat completion\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history = chat_history,\n",
    "    settings = execution_settings,\n",
    ")\n",
    "\n",
    "print(f\"AI Inference Answer: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
